#!/usr/bin/env python3
"""
å¿«é€Ÿ LLM API æµ‹è¯•è„šæœ¬

ç®€å•å¿«é€Ÿåœ°æµ‹è¯•å•ä¸ªLLMæ¨¡å‹è°ƒç”¨
"""

import asyncio
import os
import sys
import time
from dotenv import load_dotenv

# å¯¼å…¥LLMç»„ä»¶
try:
    from pkg.core.llm import (
        OpenAIProvider,
        DeepSeekProvider,
        Message,
        MessageRole,
        ChatCompletionRequest
    )
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    sys.exit(1)


async def quick_test_openai(message: str = "Hello! Please respond in Chinese."):
    """å¿«é€Ÿæµ‹è¯•OpenAI"""
    print("ğŸ” æµ‹è¯• OpenAI...")
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or api_key.startswith("sk-test"):
        print("âš ï¸  è·³è¿‡ OpenAI (æ— æœ‰æ•ˆAPIå¯†é’¥)")
        return
    
    try:
        # åˆ›å»ºProvider
        provider = OpenAIProvider.create_simple(
            api_key=api_key,
            model_name="gpt-3.5-turbo",
            base_url=os.getenv("OPENAI_API_BASE_URL", "https://api.openai.com/v1")
        )
        
        await provider.initialize_all_models()
        client = provider.get_llm_client("gpt-3.5-turbo")
        
        # åˆ›å»ºè¯·æ±‚
        request = ChatCompletionRequest(
            model="gpt-3.5-turbo",
            messages=[Message(role=MessageRole.USER, content=message)],
            max_tokens=100
        )
        
        # æ‰§è¡Œè¯·æ±‚
        print(f"  ğŸ“¤ å‘é€æ¶ˆæ¯: {message}")
        start_time = time.time()
        
        response = await client.chat_completion(request)
        
        duration = time.time() - start_time
        content = response.choices[0].message.content if response.choices else "æ— å“åº”"
        tokens = response.usage.total_tokens if response.usage else 0
        
        print(f"  âœ… OpenAI å“åº” ({duration:.2f}s, {tokens} tokens):")
        print(f"     {content}")
        
        # await provider.close_all()  # æš‚æ—¶æ³¨é‡Šæ‰ï¼Œé¿å…æ–¹æ³•ä¸å­˜åœ¨çš„é”™è¯¯
        
    except Exception as e:
        print(f"  âŒ OpenAI å¤±è´¥: {e}")


async def quick_test_deepseek(message: str = "Hello! Please respond in Chinese."):
    """å¿«é€Ÿæµ‹è¯•DeepSeek"""
    print("\nğŸ” æµ‹è¯• DeepSeek...")
    
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key or api_key.startswith("test-"):
        print("âš ï¸  è·³è¿‡ DeepSeek (æ— æœ‰æ•ˆAPIå¯†é’¥)")
        return
    
    try:
        # åˆ›å»ºProvider
        provider = DeepSeekProvider.create_simple(
            api_key=api_key,
            model_name="deepseek-chat",
            base_url=os.getenv("DEEPSEEK_API_BASE_URL", "https://api.deepseek.com/v1")
        )
        
        await provider.initialize_all_models()
        client = provider.get_llm_client("deepseek-chat")
        
        # åˆ›å»ºè¯·æ±‚
        request = ChatCompletionRequest(
            model="deepseek-chat",
            messages=[Message(role=MessageRole.USER, content=message)],
            max_tokens=100
        )
        
        # æ‰§è¡Œè¯·æ±‚
        print(f"  ğŸ“¤ å‘é€æ¶ˆæ¯: {message}")
        start_time = time.time()
        
        response = await client.chat_completion(request)
        
        duration = time.time() - start_time
        content = response.choices[0].message.content if response.choices else "æ— å“åº”"
        tokens = response.usage.total_tokens if response.usage else 0
        
        print(f"  âœ… DeepSeek å“åº” ({duration:.2f}s, {tokens} tokens):")
        print(f"     {content}")
        
        # await provider.close_all()  # æš‚æ—¶æ³¨é‡Šæ‰ï¼Œé¿å…æ–¹æ³•ä¸å­˜åœ¨çš„é”™è¯¯
        
    except Exception as e:
        print(f"  âŒ DeepSeek å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("âš¡ LLM Services å¿«é€Ÿ API æµ‹è¯•")
    print("=" * 50)
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    env_file = "deployment/.env"
    if os.path.exists(env_file):
        load_dotenv(env_file)
        print(f"ğŸ“‹ å·²åŠ è½½é…ç½®: {env_file}")
    else:
        print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {env_file}")
        print("ğŸ’¡ è¯·åˆ›å»ºé…ç½®æ–‡ä»¶å¹¶æ·»åŠ APIå¯†é’¥")
        return
    
    # è‡ªå®šä¹‰æµ‹è¯•æ¶ˆæ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
    test_message = sys.argv[1] if len(sys.argv) > 1 else "ä½ å¥½ï¼è¯·ç”¨ä¸­æ–‡ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"
    print(f"ğŸ’¬ æµ‹è¯•æ¶ˆæ¯: {test_message}")
    print()
    
    # æµ‹è¯•å„ä¸ªProvider
    await quick_test_openai(test_message)
    await quick_test_deepseek(test_message)
    
    print("\nğŸ‰ å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")
    print("ğŸ’¡ æç¤º: ä½¿ç”¨ 'python3 quick_test.py \"ä½ çš„æ¶ˆæ¯\"' è‡ªå®šä¹‰æµ‹è¯•æ¶ˆæ¯")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•å¤±è´¥: {e}") 