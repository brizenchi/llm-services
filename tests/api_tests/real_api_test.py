#!/usr/bin/env python3
"""
çœŸå® LLM API æµ‹è¯•è„šæœ¬

æ ¹æ® deployment/.env é…ç½®æ–‡ä»¶ï¼Œæµ‹è¯•çœŸå®çš„ LLM API è°ƒç”¨
"""

import asyncio
import os
import sys
import traceback
from pathlib import Path
from typing import Dict, Any, List
import time

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv

# å¯¼å…¥LLMç»„ä»¶
try:
    from pkg.core.llm import (
        get_manager,
        OpenAIProvider,
        DeepSeekProvider,
        ModelConfig,
        ProviderConfig,
        Message,
        MessageRole,
        ChatCompletionRequest,
        LLMAggregator
    )
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


class RealAPITester:
    """çœŸå®APIæµ‹è¯•å™¨"""
    
    def __init__(self, env_file: str = "deployment/.env"):
        self.env_file = env_file
        self.manager = get_manager()
        self.providers_config = {}
        self.test_results = []
        
    def load_config(self):
        """åŠ è½½ç¯å¢ƒé…ç½®"""
        print(f"ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶: {self.env_file}")
        
        if not os.path.exists(self.env_file):
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.env_file}")
            return False
            
        load_dotenv(self.env_file)
        
        # æ£€æŸ¥å¿…è¦çš„é…ç½®
        configs = {
            "openai": {
                "api_key": os.getenv("OPENAI_API_KEY"),
                "base_url": os.getenv("OPENAI_API_BASE_URL", "https://api.openai.com/v1"),
                "timeout": float(os.getenv("OPENAI_TIMEOUT", "30")),
                "max_retries": int(os.getenv("OPENAI_MAX_RETRIES", "3"))
            },
            "deepseek": {
                "api_key": os.getenv("DEEPSEEK_API_KEY"),
                "base_url": os.getenv("DEEPSEEK_API_BASE_URL", "https://api.deepseek.com/v1"),
                "timeout": float(os.getenv("DEEPSEEK_TIMEOUT", "30")),
                "max_retries": int(os.getenv("DEEPSEEK_MAX_RETRIES", "3"))
            }
        }
        
        # åªä¿ç•™æœ‰API Keyçš„é…ç½®
        for provider_name, config in configs.items():
            if config["api_key"] and config["api_key"].strip():
                if not config["api_key"].startswith("sk-test") and not config["api_key"].startswith("test-"):
                    self.providers_config[provider_name] = config
                    print(f"âœ… å‘ç° {provider_name.upper()} é…ç½®")
                else:
                    print(f"âš ï¸  è·³è¿‡ {provider_name.upper()} (æµ‹è¯•å¯†é’¥)")
            else:
                print(f"âš ï¸  è·³è¿‡ {provider_name.upper()} (æ— APIå¯†é’¥)")
        
        if not self.providers_config:
            print("âŒ æ²¡æœ‰å‘ç°æœ‰æ•ˆçš„APIé…ç½®")
            print("ğŸ’¡ è¯·åœ¨ deployment/.env ä¸­é…ç½®çœŸå®çš„APIå¯†é’¥")
            return False
            
        return True
    
    async def setup_providers(self):
        """è®¾ç½®çœŸå®çš„Provider"""
        print("\nğŸ”§ è®¾ç½® LLM Providers...")
        
        self.manager.clear()
        
        for provider_name, config in self.providers_config.items():
            try:
                if provider_name == "openai":
                    # æµ‹è¯•å¸¸è§çš„OpenAIæ¨¡å‹
                    models = ["gpt-3.5-turbo", "gpt-4o"]
                    provider = None
                    
                    for model in models:
                        try:
                            provider = OpenAIProvider.create_simple(
                                api_key=config["api_key"],
                                model_name=model,
                                base_url=config["base_url"],
                                # timeout=config["timeout"],
                                # max_retries=config["max_retries"]
                            )
                            await provider.initialize_all_models()
                            self.manager.register_provider(provider)
                            print(f"  âœ… OpenAI {model}")
                            break
                        except Exception as e:
                            print(f"  âš ï¸  OpenAI {model} ä¸å¯ç”¨: {str(e)[:1000]}...")
                            continue
                    
                elif provider_name == "deepseek":
                    # æµ‹è¯•DeepSeekæ¨¡å‹
                    models = ["deepseek-chat"]
                    
                    for model in models:
                        try:
                            provider = DeepSeekProvider.create_simple(
                                api_key=config["api_key"],
                                model_name=model,
                                base_url=config["base_url"],
                                # timeout=config["timeout"],
                                # max_retries=config["max_retries"]
                            )
                            await provider.initialize_all_models()
                            self.manager.register_provider(provider)
                            print(f"  âœ… DeepSeek {model}")
                            break
                        except Exception as e:
                            print(f"  âš ï¸  DeepSeek {model} ä¸å¯ç”¨: {str(e)[:1000]}...")
                            continue
                            
            except Exception as e:
                print(f"  âŒ {provider_name.upper()} è®¾ç½®å¤±è´¥: {e}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸæ³¨å†Œçš„Provider
        all_providers = self.manager.get_all_providers()
        if not all_providers:
            print("âŒ æ²¡æœ‰æˆåŠŸæ³¨å†Œä»»ä½•Provider")
            return False
            
        print(f"âœ… æˆåŠŸæ³¨å†Œ {len(all_providers)} ä¸ªProvider")
        return True
    
    async def test_single_model(self, provider_name: str, model_name: str, test_message: str = "Hello! Please respond in Chinese."):
        """æµ‹è¯•å•ä¸ªæ¨¡å‹"""
        print(f"\nğŸ” æµ‹è¯• {provider_name}/{model_name}")
        
        try:
            # è·å–å®¢æˆ·ç«¯
            client = self.manager.get_llm_client(provider_name, model_name)
            
            # åˆ›å»ºè¯·æ±‚
            request = ChatCompletionRequest(
                model=model_name,
                messages=[
                    Message(role=MessageRole.USER, content=test_message)
                ],
                max_tokens=100,
                temperature=0.7
            )
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # æ‰§è¡Œè¯·æ±‚
            response = await client.chat_completion(request)
            
            # è®¡ç®—è€—æ—¶
            duration = time.time() - start_time
            
            # æå–å“åº”å†…å®¹
            content = response.choices[0].message.content if response.choices else "æ— å“åº”"
            
            result = {
                "provider": provider_name,
                "model": model_name,
                "status": "success",
                "duration": duration,
                "content": content,
                "tokens_used": response.usage.total_tokens if response.usage else 0
            }
            
            print(f"  âœ… å“åº” ({duration:.2f}s, {result['tokens_used']} tokens):")
            print(f"     {content[:100]}{'...' if len(content) > 100 else ''}")
            
            self.test_results.append(result)
            return result
            
        except Exception as e:
            error_msg = str(e)
            result = {
                "provider": provider_name,
                "model": model_name,
                "status": "error",
                "error": error_msg
            }
            
            print(f"  âŒ å¤±è´¥: {error_msg}")
            self.test_results.append(result)
            return result
    
    async def test_all_models(self):
        """æµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        print("\nğŸš€ å¼€å§‹æµ‹è¯•æ‰€æœ‰æ¨¡å‹...")
        
        all_provider_names = self.manager.get_all_providers()
        test_messages = [
            "Hello! Please introduce yourself in Chinese.",
            "ç”¨ä¸­æ–‡å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—ã€‚",
            "What is 2+2? Please explain in Chinese."
        ]
        
        for i, message in enumerate(test_messages, 1):
            print(f"\nğŸ“ æµ‹è¯•æ¶ˆæ¯ {i}: {message}")
            
            for provider_name in all_provider_names:
                try:
                    provider = self.manager.get_provider(provider_name)
                    for model_name in provider.clients.keys():
                        await self.test_single_model(provider_name, model_name, message)
                        # çŸ­æš‚å»¶è¿Ÿé¿å…APIé™æµ
                        await asyncio.sleep(0.5)
                except Exception as e:
                    print(f"  âŒ è·³è¿‡ Provider {provider_name}: {e}")
    
    async def test_aggregator(self):
        """æµ‹è¯•èšåˆå™¨åŠŸèƒ½"""
        print("\nğŸ”„ æµ‹è¯• LLM èšåˆå™¨...")
        
        try:
            # è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
            available_models = []
            for provider_name in self.manager.get_all_providers():
                try:
                    provider = self.manager.get_provider(provider_name)
                    for model_name in provider.clients.keys():
                        available_models.append(model_name)
                except Exception as e:
                    print(f"  âš ï¸  è·³è¿‡ Provider {provider_name}: {e}")
                    continue
            
            if not available_models:
                print("âŒ æ²¡æœ‰å¯ç”¨æ¨¡å‹è¿›è¡Œèšåˆæµ‹è¯•")
                return
            
            # åˆ›å»ºèšåˆå™¨
            aggregator = LLMAggregator(models=available_models[:2])  # æœ€å¤šä½¿ç”¨2ä¸ªæ¨¡å‹
            aggregator.manager = self.manager
            aggregator._initialized = True
            
            # æµ‹è¯•ç”Ÿæˆå“åº”
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”ã€‚"},
                {"role": "user", "content": "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹ã€‚"}
            ]
            
            start_time = time.time()
            response = await aggregator.generate_response(messages)
            duration = time.time() - start_time
            
            print(f"  âœ… èšåˆå™¨å“åº” ({duration:.2f}s):")
            print(f"     {response[:200]}{'...' if len(response) > 200 else ''}")
            
            # æµ‹è¯•å¥åº·æ£€æŸ¥
            health = await aggregator.health_check()
            print(f"  âœ… å¥åº·æ£€æŸ¥: {health}")
            
            await aggregator.close()
            
        except Exception as e:
            print(f"  âŒ èšåˆå™¨æµ‹è¯•å¤±è´¥: {e}")
            traceback.print_exc()
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 60)
        
        if not self.test_results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return
        
        success_count = sum(1 for r in self.test_results if r["status"] == "success")
        total_count = len(self.test_results)
        
        print(f"æ€»æµ‹è¯•æ•°: {total_count}")
        print(f"æˆåŠŸ: {success_count}")
        print(f"å¤±è´¥: {total_count - success_count}")
        print(f"æˆåŠŸç‡: {success_count/total_count*100:.1f}%")
        
        print("\nğŸ“ˆ è¯¦ç»†ç»“æœ:")
        
        # æŒ‰Provideråˆ†ç»„
        by_provider = {}
        for result in self.test_results:
            provider = result["provider"]
            if provider not in by_provider:
                by_provider[provider] = []
            by_provider[provider].append(result)
        
        for provider_name, results in by_provider.items():
            print(f"\nğŸ”¹ {provider_name.upper()}:")
            for result in results:
                status_icon = "âœ…" if result["status"] == "success" else "âŒ"
                model = result["model"]
                
                if result["status"] == "success":
                    duration = result.get("duration", 0)
                    tokens = result.get("tokens_used", 0)
                    print(f"  {status_icon} {model}: {duration:.2f}s, {tokens} tokens")
                else:
                    error = result.get("error", "æœªçŸ¥é”™è¯¯")
                    print(f"  {status_icon} {model}: {error[:50]}...")
        
        # æ€§èƒ½ç»Ÿè®¡
        success_results = [r for r in self.test_results if r["status"] == "success"]
        if success_results:
            durations = [r["duration"] for r in success_results if "duration" in r]
            if durations:
                avg_duration = sum(durations) / len(durations)
                print(f"\nâš¡ å¹³å‡å“åº”æ—¶é—´: {avg_duration:.2f}ç§’")
    
    async def run_full_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        print("ğŸ§ª LLM Services çœŸå® API æµ‹è¯•")
        print("=" * 60)
        
        # 1. åŠ è½½é…ç½®
        if not self.load_config():
            return False
        
        # 2. è®¾ç½®Provider
        if not await self.setup_providers():
            return False
        
        # 3. æµ‹è¯•æ‰€æœ‰æ¨¡å‹
        await self.test_all_models()
        
        # 4. æµ‹è¯•èšåˆå™¨
        await self.test_aggregator()
        
        # 5. æ‰“å°æ€»ç»“
        self.print_summary()
        
        # 6. æ¸…ç†
        await self.manager.close_all()
        
        return True


async def main():
    """ä¸»å‡½æ•°"""
    try:
        tester = RealAPITester()
        success = await tester.run_full_test()
        
        if success:
            print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
        else:
            print("\nğŸ’¥ æµ‹è¯•å¤±è´¥ï¼")
            print("ğŸ’¡ è¯·æ£€æŸ¥ deployment/.env é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main()) 